{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a54b56c-add7-41f9-a063-ff8539e92488",
   "metadata": {},
   "source": [
    "## 4.0. Introduction to ML Libraries\n",
    "\n",
    "**Learning Objectives:** By the end of the lesson, students should have a basic understanding of the key Python libraries used in machine learning, how to use them for simple tasks, and where to go for further learning.\n",
    "\n",
    "Python is a popular programming language for data science and machine learning because of its simple syntax and the powerful libraries it offers. Python offers a rich ecosystem of machine learning libraries that provide a wide range of tools and functionalities, from data preprocessing and model training to evaluation and deployment. These libraries are well-established, actively maintained, and widely used in both research and industry.\n",
    "\n",
    "**Overview of a Typical Machine Learning Workflow:**\n",
    "1. Data Collection: Gathering the raw data, often in CSV, Excel, or SQL database format.\n",
    "2. Data Preprocessing: Cleaning and transforming data with Pandas (e.g., handling missing values, scaling features).\n",
    "3. Model Selection: Choosing an appropriate model (e.g., regression, classification, clustering) from scikit-learn, TensorFlow, or XGBoost.\n",
    "4. Training: Training the model on the data, adjusting hyperparameters.\n",
    "5. Model Evaluation: Using evaluation metrics like accuracy, precision, recall, RMSE, etc., to assess model performance.\n",
    "6. Model Deployment: Once a model is trained and evaluated, it can be deployed into production systems (using Flask, FastAPI, or TensorFlow Serving for model inference).\n",
    "\n",
    "## 4.1. Scikit-learn (for general machine learning tasks)\n",
    "Scikit-learn (often abbreviated as sklearn) is one of the most popular and accessible machine learning libraries. It provides simple and efficient tools for data mining and data analysis, built on top of NumPy, SciPy, and matplotlib. Scikit-learn is designed to be user-friendly and easy to integrate with other libraries like Pandas.\n",
    "\n",
    "**Key Features:**\n",
    "\n",
    "* **Supervised learning:** Classification, regression (e.g., SVM, decision trees, random forests, etc.)\n",
    "* **Unsupervised learning:** Clustering (e.g., K-means, DBSCAN), dimensionality reduction (e.g., PCA, t-SNE)\n",
    "* **Model selection:** Cross-validation, hyperparameter tuning (GridSearchCV, RandomizedSearchCV)\n",
    "* **Preprocessing:** Scaling, encoding categorical variables, handling missing values, etc.\n",
    "* **Metrics:** Accuracy, precision, recall, ROC-AUC, confusion matrices, etc.\n",
    "\n",
    "**Example usage:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f73284b-1fad-42cd-9493-7280e691a243",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Example: Random Forest on Iris dataset\n",
    "from sklearn.datasets import load_iris\n",
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize and fit a Random Forest classifier\n",
    "model = RandomForestClassifier(n_estimators=100)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c26c8cb-0cf1-45e2-93ae-cd165703638b",
   "metadata": {},
   "source": [
    "## 4.2. TensorFlow (for deep learning)\n",
    "TensorFlow is an open-source framework developed by Google primarily for deep learning and neural networks. It offers extensive tools for building and deploying machine learning models, especially for deep learning and artificial intelligence (AI) applications. TensorFlow 2.x is more user-friendly and tightly integrated with Keras (an API for building neural networks).\n",
    "\n",
    "**Key Features:**\n",
    "* **Deep learning:** Neural networks, CNNs (Convolutional Neural Networks), RNNs (Recurrent Neural Networks), GANs (Generative Adversarial Networks), and more.\n",
    "* **High-level APIs:** Keras integration for easy model building.\n",
    "* **Scalability:** Works across CPUs, GPUs, and TPUs for high performance.\n",
    "* **Ecosystem:** Tools for deploying models in production (TensorFlow Serving, TensorFlow Lite), and serving models on mobile and edge devices.\n",
    "  \n",
    "**Example usage:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a4eed8-ab10-4813-8b35-159eaf2d07d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# Load dataset\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Preprocess the data\n",
    "X_train = X_train.reshape(-1, 28*28).astype('float32') / 255\n",
    "X_test = X_test.reshape(-1, 28*28).astype('float32') / 255\n",
    "\n",
    "# Build a simple neural network\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(28*28,)),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=5)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(\"Test accuracy:\", test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad22fd4-5cb2-4ed9-a77a-10d743851007",
   "metadata": {},
   "source": [
    "## 4.3. PyTorch (for deep learning)\n",
    "PyTorch is an open-source deep learning library developed by Facebook's AI Research lab. It provides a flexible and dynamic approach to building deep learning models. PyTorch is known for its dynamic computational graph, which makes it more intuitive for research and experimentation, and itâ€™s widely used in academic research.\n",
    "\n",
    "**Key Features:**\n",
    "* **Dynamic computation graphs (eager execution):** Offers flexibility to change the network during runtime.\n",
    "* **Deep learning:** Tools for CNNs, RNNs, transformers, etc.\n",
    "* **Autograd:** Automatic differentiation for gradient-based optimization.\n",
    "* **Deployment:** PyTorch provides tools for model deployment, including TorchServe for serving models.\n",
    "\n",
    "**Example usage:**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c9a7ec-ebcc-4b62-8463-4700a104df66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Load data (MNIST)\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "train_data = datasets.MNIST('.', train=True, download=True, transform=transform)\n",
    "\n",
    "# DataLoader for batch processing\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "\n",
    "# Define a simple neural network\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, 1)  # Flatten the image\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the network and loss function\n",
    "model = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(5):\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f77797-5184-42fb-af1c-044774fc76a0",
   "metadata": {},
   "source": [
    "## 4.4. Keras (for high-level deep learning)\n",
    "Keras is a high-level API for building deep learning models, and it is now tightly integrated with TensorFlow. It allows users to define and train neural networks in a simpler and more user-friendly way. Although Keras is now part of TensorFlow, it is still available as a standalone library in some cases.\n",
    "\n",
    "**Key Features:**\n",
    "* **Simple API:** Makes it easy to define, train, and evaluate models.\n",
    "* **Deep learning models:** Fully connected networks, CNNs, RNNs, etc.\n",
    "* **Model deployment:** Keras models can be easily exported and deployed.\n",
    "\n",
    "**Example usage:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5484635f-6005-4109-bff3-c943f380556d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.datasets import mnist\n",
    "\n",
    "# Load dataset\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Preprocess the data\n",
    "X_train = X_train.reshape(-1, 28*28).astype('float32') / 255\n",
    "X_test = X_test.reshape(-1, 28*28).astype('float32') / 255\n",
    "\n",
    "# Build a simple neural network\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(28*28,)),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=5)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(\"Test accuracy:\", test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e25e405-5061-40fa-b827-a1d9eeb6178d",
   "metadata": {},
   "source": [
    "## 4.5. XGBoost (for gradient boosting and ensemble learning)\n",
    "XGBoost is an optimized gradient boosting library designed for high performance and speed. It is widely used for structured/tabular data and is known for winning many Kaggle competitions.\n",
    "\n",
    "**Key Features:**\n",
    "* **Gradient boosting:** A powerful ensemble technique for boosting the accuracy of decision trees.\n",
    "* **Efficiency:** Known for its speed and performance, particularly with large datasets.\n",
    "* **Regularization:** Built-in regularization to prevent overfitting.\n",
    "* **Cross-validation:** Built-in functionality for cross-validation during training.\n",
    "\n",
    "**Example usage:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4e24b4-05e5-4d88-81e8-924e20e9a661",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load dataset\n",
    "data = load_boston()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train XGBoost model\n",
    "model = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, learning_rate=0.1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_test)\n",
    "print(\"Test MSE:\", mse)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c754e3b5-91a1-420a-bf06-74eaffcca507",
   "metadata": {},
   "source": [
    "**Task/Homework:** Build a simple machine learning or neural network model using various Python libraries and data for various tasks (such as classification or regression tasks)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
